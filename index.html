---
layout: default
title: Sasha Vtyurina
---
<div class="blurb">
  <h1>Sasha Vtyurina</h1>

   <img class="portrait" src="SashaPortraitBWGrainy.jpg" alt="Portrait photo of Sasha" width="500"> 

    <p> Hi! My name is Sasha. I live in Toronto, Canada and work at Zuva as a Research Scientist for User Behaviour. My work has quantitative and qualitative aspects to it. I design and run user studies, distill insights through thematic analysis, compile reports to help prioritise the process of development. I have also worked on quantitatve analysis of user event logs with the goal of finding high level events that can explain user activity and goals. </p>

    <p>Broadly speaking, I am interested in understanding people's usage of technology and improving said technology to suit users better. Throughout my PhD I focused on voice-based interactions between humans and computer systems. In particular, I have been studying how such interactions can be used to facilitate the process of information finding, and web search specifically. In one of my projects, I explored how voice-based web search can be useful for people who are blind or visually impaired. </p>

  <h2>General life updates</h2>
  <!-- <p class="footnote">*related to academia and not.</p> -->

    <div class="news">
      <div class="date">Septermber, 2021</div>
      <div class="content">
        As <a href="https://kirasystems.com/company-announcements/litera-acquires-kira-systems/">Kira Systems got acquired by Litera</a>, <a href="https://zuva.ai/">ZuvaAI</a> was spun off as a child company. I stayed with the Zuva team to continue user behaviour analysis work. Now with a new product!
      </div>
    </div>

    <div class="news">
      <div class="date">August, 2020</div>
      <div class="content">
        Our paper <a href="papers/vtyurina2020audioSerp.pdf">A Mixed-Method Analysis of Text and Audio Search Interfaces with Varying Task Complexity</a> was accepted at ICTIR 2020. In short, in it we ponder how one might represent a search result using an audio-only channel. By the way, I also recorded <a href="https://youtu.be/oH3yJE2dPs0">a talk for it</a>.
      </div>
    </div>

    <div class="news">
      <div class="date">May, 2020</div>
      <div class="content">
        I am excited to announce that I started my work at <a href="https://kirasystems.com/">Kira Systems</a> as a Research Scientist for User Behaviour!
      </div>
    </div>

     <div class="news">
      <div class="date">October, 2019</div>
      <div class="content">I ran my first full marathon! I might write a bit about it later.</div>
    </div>

    <div class="news">
      <div class="date">August, 2019</div>
      <div class="content">Our paper <a href="papers/VERSE_ASSETS2019.pdf">VERSE: Bridging Screen Readers and Voice Assistants for Enhanced Eyes-Free Web Search</a> was accepted to ASSETS 2019. It received a best paper nomination (but not the award) which I was quite content about. At the time of acceptance it also generated some interest in the press:
        <ul>
            <li><a href="https://www.therecord.com/news-story/9559442-uw-student-helps-to-develop-online-accessibility-tool/">The Record: UW student helps to develop online accessibility tool.</a></li>
            <li><a href="https://nypost.com/2019/08/20/new-tool-helps-the-visually-impaired-surf-the-web/">New York Post: New tool helps the visually impaired surf the web.</a></li>
            <li><a href="https://uwaterloo.ca/news/news/new-tool-makes-web-browsing-easier-visually-impaired">University of Waterloo: New tool makes web browsing easier for the visually impaired.</a></li>
            <li><a href="https://technews.acm.org/archives.cfm?fo=2019-08-aug/aug-21-2019.html">The story was also featured in the ACM TechNews.</a></li>
          </ul>
      </div>
    </div>

</div><!-- /.blurb -->
